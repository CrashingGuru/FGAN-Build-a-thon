{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vrra/FGAN-Build-a-thon/blob/main/Notebooks2023/Argilla_configure_dataset-v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ba716c0",
      "metadata": {
        "id": "9ba716c0"
      },
      "source": [
        "<div class=\"alert alert-info\">\n",
        "\n",
        "Note\n",
        "    \n",
        "This tutorial demonstrates a sample usage for `FeedbackDataset`, which offers implementations different from the old `TextClassificationDataset`, `Text2TextDataset` and `TokenClassificationDataset`. To have info about old datasets, you can have a look at them [here]([../getting_started/quickstart_workflow.html](https://docs.argilla.io/en/latest/getting_started/quickstart_workflow.html)). Not sure which dataset to use? Check out our section on [choosing a dataset](https://docs.argilla.io/en/latest/practical_guides/choose_dataset.html).\n",
        "    \n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b1cd645",
      "metadata": {
        "id": "8b1cd645"
      },
      "source": [
        "# Workflow Feedback Dataset\n",
        "\n",
        "Argilla Feedback is a tool designed to obtain and manage both the feedback data from annotators and the suggestions from small and large language models.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fbc7acc7",
      "metadata": {
        "id": "fbc7acc7"
      },
      "source": [
        "## Install Libraries\n",
        "\n",
        "Install the latest version of Argilla in Colab, along with other libraries and models used in this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "f808bb22",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f808bb22",
        "outputId": "811edff5-2692-4bf9-84a3-25ff0a36b42d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting argilla\n",
            "  Downloading argilla-1.21.0-py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets\n",
            "  Downloading datasets-2.16.0-py3-none-any.whl (507 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.1/507.1 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting setfit\n",
            "  Downloading setfit-1.0.1-py3-none-any.whl (74 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.2/74.2 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting evaluate\n",
            "  Downloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting httpx<=0.25,>=0.15 (from argilla)\n",
            "  Downloading httpx-0.25.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.7/75.7 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting deprecated~=1.2.0 (from argilla)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from argilla) (23.2)\n",
            "Requirement already satisfied: pandas<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from argilla) (1.5.3)\n",
            "Requirement already satisfied: pydantic<2.0,>=1.10.7 in /usr/local/lib/python3.10/dist-packages (from argilla) (1.10.13)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.13 in /usr/local/lib/python3.10/dist-packages (from argilla) (1.14.1)\n",
            "Requirement already satisfied: numpy<1.24.0 in /usr/local/lib/python3.10/dist-packages (from argilla) (1.23.5)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.10/dist-packages (from argilla) (4.66.1)\n",
            "Collecting backoff (from argilla)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Collecting monotonic (from argilla)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: rich!=13.1.0 in /usr/local/lib/python3.10/dist-packages (from argilla) (13.7.0)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from argilla) (0.9.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.1)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (10.0.1)\n",
            "Collecting pyarrow-hotfix (from datasets)\n",
            "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.19.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Collecting sentence-transformers>=2.2.1 (from setfit)\n",
            "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from setfit) (1.2.2)\n",
            "Collecting responses<0.19 (from evaluate)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<=0.25,>=0.15->argilla) (2023.11.17)\n",
            "Collecting httpcore<0.19.0,>=0.18.0 (from httpx<=0.25,>=0.15->argilla)\n",
            "  Downloading httpcore-0.18.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<=0.25,>=0.15->argilla) (3.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<=0.25,>=0.15->argilla) (1.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.0.0,>=1.0.0->argilla) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.0.0,>=1.0.0->argilla) (2023.3.post1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich!=13.1.0->argilla) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich!=13.1.0->argilla) (2.16.1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->setfit) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->setfit) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->setfit) (3.2.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.2.1->setfit) (4.35.2)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.2.1->setfit) (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.2.1->setfit) (0.16.0+cu121)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.2.1->setfit) (3.8.1)\n",
            "Collecting sentencepiece (from sentence-transformers>=2.2.1->setfit)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.6.0->argilla) (8.1.7)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from httpcore<0.19.0,>=0.18.0->httpx<=0.25,>=0.15->argilla) (3.7.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore<0.19.0,>=0.18.0->httpx<=0.25,>=0.15->argilla)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich!=13.1.0->argilla) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas<2.0.0,>=1.0.0->argilla) (1.16.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers>=2.2.1->setfit) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers>=2.2.1->setfit) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers>=2.2.1->setfit) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers>=2.2.1->setfit) (2.1.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=2.2.1->setfit) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=2.2.1->setfit) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=2.2.1->setfit) (0.4.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence-transformers>=2.2.1->setfit) (9.4.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->httpcore<0.19.0,>=0.18.0->httpx<=0.25,>=0.15->argilla) (1.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence-transformers>=2.2.1->setfit) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence-transformers>=2.2.1->setfit) (1.3.0)\n",
            "Building wheels for collected packages: seqeval, sentence-transformers\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=1741a14670fa3ed278dc1c3e323a3b1777867f91d1eb6472182b241aa38d9fe6\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125923 sha256=f3c6aeaee9ad5ad2fe3e4fe216217801053e31e27f8ed4aed58798edbf061bc9\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n",
            "Successfully built seqeval sentence-transformers\n",
            "Installing collected packages: sentencepiece, monotonic, pyarrow-hotfix, h11, dill, deprecated, backoff, responses, multiprocess, httpcore, seqeval, httpx, datasets, argilla, sentence-transformers, evaluate, setfit\n",
            "Successfully installed argilla-1.21.0 backoff-2.2.1 datasets-2.16.0 deprecated-1.2.14 dill-0.3.7 evaluate-0.4.1 h11-0.14.0 httpcore-0.18.0 httpx-0.25.0 monotonic-1.6 multiprocess-0.70.15 pyarrow-hotfix-0.6 responses-0.18.0 sentence-transformers-2.2.2 sentencepiece-0.1.99 seqeval-1.2.2 setfit-1.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install argilla datasets setfit evaluate seqeval"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "EwDfn8E7W7jD",
      "metadata": {
        "id": "EwDfn8E7W7jD"
      },
      "source": [
        "## Set Up Argilla\n",
        "\n",
        "If you have already deployed Argilla Server, then you can skip this step. Otherwise, you can quickly deploy it in two different ways:\n",
        "\n",
        "* You can deploy Argilla Server on [HF Spaces](https://huggingface.co/new-space?template=argilla/argilla-template-space).\n",
        "\n",
        "* Alternatively, if you want to run Argilla locally on your own computer, the easiest way to get Argilla UI up and running is to deploy on Docker:\n",
        "\n",
        "    ```\n",
        "    docker run -d --name quickstart -p 6900:6900 argilla/argilla-quickstart:latest\n",
        "    ```\n",
        "\n",
        "More info on Installation [here](../getting_started/installation/deployments/deployments.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00b2e199",
      "metadata": {
        "id": "00b2e199"
      },
      "source": [
        "## Connect to Argilla\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a93bc742",
      "metadata": {
        "id": "a93bc742"
      },
      "source": [
        "It is possible to connect to our Argilla instance by simply importing the Argilla library and using the environment variables and `rg.init()`.\n",
        "\n",
        "* `ARGILLA_API_URL`: It is the url of the Argilla Server.\n",
        "  * If you're using Docker, it is `http://localhost:6900` by default.\n",
        "  * If you're using HF Spaces, it is constructed as `https://[your-owner-name]-[your_space_name].hf.space`.\n",
        "* `ARGILLA_API_KEY`: It is the API key of the Argilla Server. It is `owner` by default.\n",
        "* `HF_TOKEN`: It is the Hugging Face API token. It is only needed if you're using a [private HF Space](https://docs.argilla.io/en/latest/getting_started/installation/deployments/huggingface-spaces.html#deploy-argilla-on-spaces). You can configure it in your profile: [Setting > Access Tokens](https://huggingface.co/settings/tokens).\n",
        "* `workspace`: It is a “space” inside your Argilla instance where authorized users can collaborate. It's `argilla` by default.\n",
        "\n",
        "For more info about custom configurations like headers, workspace separation or access credentials, check our [config page](https://docs.argilla.io/en/latest/getting_started/installation/configurations/configurations.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "215b5b39",
      "metadata": {
        "id": "215b5b39"
      },
      "outputs": [],
      "source": [
        "import argilla as rg\n",
        "from argilla._constants import DEFAULT_API_KEY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "19c56015",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19c56015",
        "outputId": "044e18d7-9f1b-425c-889b-78fd581e3246"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/argilla/client/client.py:168: UserWarning: No workspace configuration was detected. To work with Argilla datasets, specify a valid workspace name on `rg.init` or set it up through the `rg.set_workspace` function.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from google.colab import userdata\n",
        "api_url= userdata.get('my_argilla_url')\n",
        "api_key= userdata.get('my_argilla_key')\n",
        "\n",
        "import argilla as rg\n",
        "rg.init(api_url=api_url, api_key=api_key)\n",
        "\n",
        "# # If you want to use your private HF Space\n",
        "# rg.init(extra_headers={\"Authorization\": f\"Bearer {hf_token}\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmzHbpN3fy-Z"
      },
      "source": [
        "### Enable Telemetry\n",
        "\n",
        "We gain valuable insights from how you interact with our tutorials. To improve ourselves in offering you the most suitable content, using the following lines of code will help us understand that this tutorial is serving you effectively. Though this is entirely anonymous, you can choose to skip this step if you prefer. For more info, please check out the [Telemetry](../../reference/telemetry.md) page."
      ],
      "id": "qmzHbpN3fy-Z"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "nKaJ4dCbfy-Z"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    from argilla.utils.telemetry import tutorial_running\n",
        "    tutorial_running()\n",
        "except ImportError:\n",
        "    print(\"Telemetry is introduced in Argilla 1.20.0 and not found in the current installation. Skipping telemetry.\")"
      ],
      "id": "nKaJ4dCbfy-Z"
    },
    {
      "cell_type": "markdown",
      "id": "423d6483",
      "metadata": {
        "id": "423d6483"
      },
      "source": [
        "## Create a Dataset\n",
        "\n",
        "FeedbackDataset is the container for Argilla Feedback structure. Argilla Feedback offers different components for FeedbackDatasets that you can employ for various aspects of your workflow. For a more detailed explanation, refer to the [documentation](https://docs.argilla.io/en/latest/practical_guides/practical_guides.html) and the [end-to-end tutorials](https://docs.argilla.io/en/latest/tutorials_and_integrations/tutorials/tutorials.html) for beginners.\n",
        "\n",
        "To start, we need to configure the FeedbackDatasest. To do so, there are two options: use a pre-defined template or create a custom one."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4146f0d7",
      "metadata": {
        "id": "4146f0d7"
      },
      "source": [
        "### Use a Task Template\n",
        "\n",
        "Argilla offers a set of [pre-defined templates for different tasks](https://docs.argilla.io/en/latest/practical_guides/create_update_dataset/create_dataset.html#task-templates). You can use them to configure your dataset straightforward. For instance, if you want to create a dataset for simple text classification, you can use the following code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "96b161c4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96b161c4",
        "outputId": "cd8dbb42-39b1-4d4b-e612-543a2c8914af"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FeedbackDataset(\n",
              "   fields=[TextField(name='text', title='Text', required=True, type='text', use_markdown=True)]\n",
              "   questions=[LabelQuestion(name='label', title='Label', description='Classify the text by selecting the correct label from the given list of labels.', required=True, type='label_selection', labels=['joy', 'sadness'], visible_labels=None)]\n",
              "   guidelines=This is a text classification dataset that contains texts and labels. Given a set of texts and a predefined set of labels, the goal of text classification is to assign one label to each text based on its content. Please classify the texts by making the correct selection.)\n",
              "   metadata_properties=[])\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "dataset = rg.FeedbackDataset.for_text_classification(\n",
        "    labels=[\"joy\", \"sadness\"],\n",
        "    multi_label=False,\n",
        "    use_markdown=True,\n",
        "    guidelines=None,\n",
        "    metadata_properties=None,\n",
        "    vectors_settings=None,\n",
        ")\n",
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f9ca558",
      "metadata": {
        "id": "4f9ca558"
      },
      "source": [
        "Now that we have our dataset, we can\n",
        "\n",
        "*   List item\n",
        "*   List item\n",
        "\n",
        "push the dataset to the Argilla space.\n",
        "\n",
        "<div class=\"alert alert-info\">\n",
        "\n",
        "Note\n",
        "    \n",
        "From Argilla 1.14.0, calling `push_to_argilla` will not just push the `FeedbackDataset` into Argilla, but will also return the remote `FeedbackDataset` instance, which implies that the additions, updates, and deletions of records will be pushed to Argilla as soon as they are made. This is a change from previous versions of Argilla, where you had to call `push_to_argilla` again to push the changes to Argilla.\n",
        "    \n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "dc956805",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dc956805",
        "outputId": "24c3efef-96b6-43fc-98b5-15396d9cb400"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:argilla.client.feedback.dataset.local.mixins:✓ Dataset succesfully pushed to Argilla\n",
            "INFO:argilla.client.feedback.dataset.local.mixins:RemoteFeedbackDataset(\n",
            "   id=d5f89faf-a447-49b3-8c23-7dabdbb7f92a\n",
            "   name=my-first-dataset\n",
            "   workspace=Workspace(id=4313bcb9-d5d2-4889-97c3-0cdcb4772830, name=admin, inserted_at=2023-12-30 16:09:58.983219, updated_at=2023-12-30 16:09:58.983219)\n",
            "   url=https://vishnuramov-itu-t-build-a-thon.hf.space/dataset/d5f89faf-a447-49b3-8c23-7dabdbb7f92a/annotation-mode\n",
            "   fields=[RemoteTextField(id=UUID('cae469fc-9226-4955-9c37-de3b588a1fd1'), client=None, name='text', title='Text', required=True, type='text', use_markdown=True)]\n",
            "   questions=[RemoteLabelQuestion(id=UUID('931c2456-dd7e-4451-8f42-ba802b356e4b'), client=None, name='label', title='Label', description=None, required=True, type='label_selection', labels=['joy', 'sadness'], visible_labels=None)]\n",
            "   guidelines=This is a text classification dataset that contains texts and labels. Given a set of texts and a predefined set of labels, the goal of text classification is to assign one label to each text based on its content. Please classify the texts by making the correct selection.\n",
            "   metadata_properties=[]\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    dataset.push_to_argilla(name=\"my-first-dataset\", workspace=\"admin\")\n",
        "except:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2847830f",
      "metadata": {
        "id": "2847830f"
      },
      "source": [
        "### Configure a Custom Dataset\n",
        "\n",
        "If your dataset does not fit into one of the pre-defined templates, you [can create a custom dataset](https://docs.argilla.io/en/latest/practical_guides/create_update_dataset/create_dataset.html#define-questions) by defining the fields, the different question types, the metadata properties and the vectors settings."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b099e23",
      "metadata": {
        "id": "4b099e23"
      },
      "source": [
        "## Add the Records\n",
        "\n",
        "A record refers to each of the data items that will be annotated by the annotator team. The records will be the pieces of information that will be shown to the user in the UI in order to complete the annotation task. In the current dataset sample, it can only consist of a text to be labeled."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36b9b719",
      "metadata": {
        "id": "36b9b719"
      },
      "outputs": [],
      "source": [
        "records = [\n",
        "    rg.FeedbackRecord(\n",
        "        fields={\n",
        "            \"text\": \"I am so happy today\",\n",
        "        },\n",
        "    ),\n",
        "    rg.FeedbackRecord(\n",
        "        fields={\n",
        "            \"text\": \"I feel sad today\",\n",
        "        },\n",
        "    )\n",
        "]\n",
        "dataset.add_records(records)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df7d2540",
      "metadata": {
        "id": "df7d2540",
        "outputId": "2c31f724-3430-431a-acd6-f717a9329aa4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[FeedbackRecord(fields={'text': 'I am so happy today'}, metadata={}, vectors={}, responses=[], suggestions=(), external_id=None),\n",
              " FeedbackRecord(fields={'text': 'I feel sad today'}, metadata={}, vectors={}, responses=[], suggestions=(), external_id=None)]"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.records"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "850c8a0e",
      "metadata": {
        "id": "850c8a0e"
      },
      "source": [
        "Argilla also offers a way to use suggestions and responses from other models as a starting point for annotators. This way, annotators can save time and effort by correcting the predictions or answers instead of annotating from scratch."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a5a3bf3",
      "metadata": {
        "id": "5a5a3bf3"
      },
      "source": [
        "## Train a model\n",
        "\n",
        "As with other datasets, Feedback datasets also allow to create a training pipeline and make inferences with the resulting model. After you gather responses with Argilla Feedback, you can easily fine-tune an LLM. In this example, we will have to complete a text classification task.\n",
        "\n",
        "For fine-tuning, we will use setfit library and the [Argilla Trainer](https://docs.argilla.io/en/latest/practical_guides/fine_tune.html#the-argillatrainer), which is a powerful wrapper around many of our favorite NLP libraries. It provides a very intuitive abstract representation to facilitate simple training workflows using decent default pre-set configurations without having to worry about any data transformations from Argilla.\n",
        "\n",
        "Let us first create our dataset to train. For this example, we will use the [emotion](https://huggingface.co/datasets/argilla/emotion) dataset from Argilla, which was created using Argilla. Each text item has its responses as 6 different sentiments, which are Sadness, Joy, Love, Anger, Fear and Surprise."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "586059d7",
      "metadata": {
        "id": "586059d7"
      },
      "outputs": [],
      "source": [
        "# Besides Argilla, it can also be imported with load_dataset from datasets\n",
        "dataset_hf = rg.FeedbackDataset.from_huggingface(\"argilla/emotion\", split=\"train[1:101]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9286b053",
      "metadata": {
        "id": "9286b053",
        "outputId": "edc49299-e9da-41ca-d758-6c0b445829ce"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "FeedbackDataset(\n",
              "   fields=[TextField(name='text', title='Text', required=True, type=<FieldTypes.text: 'text'>, use_markdown=False)]\n",
              "   questions=[LabelQuestion(name='label', title='Label', description=None, required=True, type=<QuestionTypes.label_selection: 'label_selection'>, labels={'0': 'sadness', '1': 'joy', '2': 'love', '3': 'anger', '4': 'fear', '5': 'surprise'}, visible_labels=6)]\n",
              "   guidelines=Argilla port of [dair-ai/emotion](https://huggingface.co/datasets/dair-ai/emotion).)\n",
              "   metadata_properties=[])\n",
              ")"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset_hf"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "861c3648",
      "metadata": {
        "id": "861c3648"
      },
      "source": [
        "We can then start to create a training pipeline by first defining `TrainingTask`, which is used to define how the data should be processed and formatted according to the associated task and framework. Each task has its own classmethod and the data formatting can always be customized via `formatting_func`. You can visit [this page](https://docs.argilla.io/en/latest/practical_guides/fine_tune.html#tasks) for more info. Simpler tasks like text classification can be defined using default definitions, as we do in this example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04537510",
      "metadata": {
        "id": "04537510"
      },
      "outputs": [],
      "source": [
        "from argilla.feedback import TrainingTask\n",
        "\n",
        "task = TrainingTask.for_text_classification(\n",
        "    text=dataset_hf.field_by_name(\"text\"),\n",
        "    label=dataset_hf.question_by_name(\"label\")\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2492e2e2",
      "metadata": {
        "id": "2492e2e2"
      },
      "source": [
        "We can then define our ArgillaTrainer for any of the supported frameworks and customize the training config using ArgillaTrainer.update_config.\n",
        "\n",
        "Let us define ArgillaTrainer with any of the supported frameworks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8187adc1",
      "metadata": {
        "id": "8187adc1"
      },
      "outputs": [],
      "source": [
        "from argilla.feedback import ArgillaTrainer\n",
        "\n",
        "trainer = ArgillaTrainer(\n",
        "    dataset=dataset_hf,\n",
        "    task=task,\n",
        "    framework=\"setfit\",\n",
        "    train_size=0.8\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1bccf880",
      "metadata": {
        "id": "1bccf880"
      },
      "source": [
        "You can update the model config via `update_config`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "332a4f1d",
      "metadata": {
        "id": "332a4f1d"
      },
      "outputs": [],
      "source": [
        "trainer.update_config(num_train_epochs=1, num_iterations=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca6d7dc3",
      "metadata": {
        "id": "ca6d7dc3"
      },
      "source": [
        "We can now train the model with `train`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a144a4a8",
      "metadata": {
        "id": "a144a4a8"
      },
      "outputs": [],
      "source": [
        "trainer.train(output_dir=\"setfit_model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ae12a61",
      "metadata": {
        "id": "8ae12a61"
      },
      "source": [
        "and make inferences with `predict`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7863b92",
      "metadata": {
        "id": "d7863b92"
      },
      "outputs": [],
      "source": [
        "trainer.predict(\"This is just perfect!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85ad4ad2",
      "metadata": {
        "id": "85ad4ad2"
      },
      "source": [
        "We have trained a model with FeedbackDataset in this tutorial. For more info about concepts in Argilla Feedback and LLMs, look [here](https://docs.argilla.io/en/latest/conceptual_guides/llm/llm.html). For a more detailed explanation, refer to the [documentation](https://docs.argilla.io/en/latest/practical_guides/practical_guides.html) and the [end-to-end tutorials](https://docs.argilla.io/en/latest/tutorials_and_integrations/tutorials/tutorials.html) for beginners."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ZyEUBBjbK7k",
      "metadata": {
        "id": "2ZyEUBBjbK7k"
      },
      "source": [
        "-------------\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "vscode": {
      "interpreter": {
        "hash": "2584bca9d226488c39a669ff1ce19d7ca5f410e2d3aa9b82f20653edd0d96bfc"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}